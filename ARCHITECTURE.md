# ğŸš€ CareerForge AI - Production Architecture

> **Mission**: 100% Open-Source, Zero API Costs, Infinite Scalability

---

## ğŸ“ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CAREERFORGE AI ARCHITECTURE                             â”‚
â”‚                          (100% Open-Source, Zero API Costs)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     â”‚     â”‚                              â”‚     â”‚                    â”‚
â”‚   FRONTEND          â”‚     â”‚   BACKEND API                â”‚     â”‚   LLM SERVICE      â”‚
â”‚   (React/Vite)      â”‚     â”‚   (FastAPI/Python)           â”‚     â”‚   (Ollama)         â”‚
â”‚                     â”‚     â”‚                              â”‚     â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Landing Page  â”‚  â”‚     â”‚  â”‚ POST /api/ai/roadmap   â”‚  â”‚     â”‚  â”‚              â”‚  â”‚
â”‚  â”‚ Career Form   â”‚  â”‚â”€â”€â”€â”€â–¶â”‚  â”‚ POST /api/ai/skills    â”‚â”€â”€â”¼â”€â”€â”€â”€â–¶â”‚  â”‚  Mistral 7B  â”‚  â”‚
â”‚  â”‚ Dashboard     â”‚  â”‚     â”‚  â”‚ POST /api/ai/interview â”‚  â”‚     â”‚  â”‚  Instruct    â”‚  â”‚
â”‚  â”‚ Progress      â”‚  â”‚â—€â”€â”€â”€â”€â”‚  â”‚ POST /api/ai/quiz      â”‚â—€â”€â”¼â”€â”€â”€â”€â”€â”‚  â”‚  (Apache 2.0)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚     â”‚                              â”‚     â”‚                    â”‚
â”‚  Port: 5173         â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  REST API: 11434   â”‚
â”‚                     â”‚     â”‚  â”‚ Prompt Engineering     â”‚  â”‚     â”‚  OpenAI-compat.    â”‚
â”‚                     â”‚     â”‚  â”‚ Response Validation    â”‚  â”‚     â”‚                    â”‚
â”‚                     â”‚     â”‚  â”‚ JSON Structuring       â”‚  â”‚     â”‚  Hot-swappable:    â”‚
â”‚                     â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  - Mistral 7B âœ“    â”‚
â”‚                     â”‚     â”‚                              â”‚     â”‚  - LLaMA 3 8B      â”‚
â”‚                     â”‚     â”‚  Port: 8000                  â”‚     â”‚  - Mixtral 8x7B    â”‚
â”‚                     â”‚     â”‚                              â”‚     â”‚  - Qwen 7B         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ† Model Selection: Mistral 7B Instruct v0.3

### Why Mistral 7B?

| Criteria | Mistral 7B | LLaMA 3 8B | Mixtral 8x7B |
|----------|------------|------------|--------------|
| **License** | âœ… Apache 2.0 | âš ï¸ Meta License | âœ… Apache 2.0 |
| **Commercial Use** | âœ… Unrestricted | âš ï¸ Restrictions | âœ… Unrestricted |
| **VRAM (Q4)** | 6GB | 8GB | 24GB+ |
| **Speed** | âš¡ 127 tok/s | 67 tok/s | 45 tok/s |
| **Context** | 32K | 8K | 32K |
| **Reasoning** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |

### Key Advantages:
1. **True Apache 2.0** - Zero licensing friction for commercial use
2. **6GB VRAM** - Runs on RTX 3060/4060 consumer GPUs
3. **32K Context** - Handle detailed profiles and long roadmaps
4. **Fastest in class** - 2x faster than LLaMA 3 8B
5. **Battle-tested** - Production-proven with extensive community

---

## ğŸ“ Project Structure

```
career-forge/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                     # FastAPI application entry
â”‚   â”œâ”€â”€ config.py                   # Environment configuration
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ai_routes.py        # AI endpoint handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ health_routes.py    # Health checks
â”‚   â”‚   â”‚   â””â”€â”€ quiz_routes.py      # Quiz endpoints
â”‚   â”‚   â””â”€â”€ schemas/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ requests.py         # Request models
â”‚   â”‚       â””â”€â”€ responses.py        # Response models
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_service.py          # LLM abstraction layer
â”‚   â”‚   â”œâ”€â”€ roadmap_service.py      # Roadmap generation
â”‚   â”‚   â”œâ”€â”€ skills_service.py       # Skills analysis
â”‚   â”‚   â”œâ”€â”€ interview_service.py    # Interview prep
â”‚   â”‚   â”œâ”€â”€ quiz_service.py         # Quiz generation
â”‚   â”‚   â””â”€â”€ youtube_service.py      # YouTube scraping
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ system_prompts.py       # System prompts
â”‚   â”‚   â”œâ”€â”€ roadmap_prompts.py      # Roadmap templates
â”‚   â”‚   â””â”€â”€ quiz_prompts.py         # Quiz templates
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ json_parser.py          # Safe JSON extraction
â”‚       â””â”€â”€ validators.py           # Input validation
â”‚
â”œâ”€â”€ llm-service/
â”‚   â”œâ”€â”€ docker-compose.yml          # Ollama deployment
â”‚   â”œâ”€â”€ Modelfile                   # Custom model config
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ setup.sh                # Setup script
â”‚       â”œâ”€â”€ health-check.sh         # Health monitoring
â”‚       â””â”€â”€ benchmark.sh            # Performance testing
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ [existing React/Vite app]
â”‚
â”œâ”€â”€ docker-compose.yml              # Full stack deployment
â”œâ”€â”€ .env.example                    # Environment template
â”œâ”€â”€ ARCHITECTURE.md                 # This file
â””â”€â”€ README.md                       # Quick start guide
```

---

## ğŸ”Œ API Design

### Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/ai/roadmap` | Generate career roadmap |
| `POST` | `/api/ai/skills` | Analyze and suggest skills |
| `POST` | `/api/ai/interview-prep` | Interview preparation |
| `POST` | `/api/ai/quiz` | Generate knowledge quiz |
| `GET` | `/api/health` | Service health check |
| `GET` | `/api/health/llm` | LLM service status |

### Response Format (Roadmap)

```json
{
  "success": true,
  "data": {
    "career_role": "Full-Stack Developer",
    "overview": "...",
    "timeline": "6-9 months",
    "roadmap": [
      {
        "month": 1,
        "title": "Foundation",
        "weeks": [
          {
            "week": 1,
            "focus": "HTML & CSS Fundamentals",
            "hours": 15,
            "tasks": ["Build personal portfolio", "Complete CSS Grid course"]
          }
        ],
        "tools": ["VS Code", "Git", "Chrome DevTools"],
        "projects": [
          {
            "name": "Personal Portfolio",
            "difficulty": "beginner",
            "estimated_hours": 10
          }
        ],
        "checkpoint": "Can build responsive layouts from scratch"
      }
    ],
    "final_outcome": "...",
    "resources": {
      "official_docs": [],
      "courses": [],
      "youtube_channels": []
    }
  },
  "meta": {
    "model": "mistral:7b-instruct-v0.3",
    "latency_ms": 2450,
    "tokens_used": 1847
  }
}
```

---

## ğŸš€ Deployment Options

### 1. Local Development (FREE)

```bash
# Terminal 1: Start LLM Service (Ollama)
ollama serve
ollama pull mistral:7b-instruct-v0.3-q4_K_M

# Terminal 2: Start Backend
cd backend && uvicorn main:app --reload

# Terminal 3: Start Frontend
cd frontend && npm run dev
```

**Requirements**: 8GB+ RAM, 10GB disk for model

### 2. Single VPS ($20-50/month)

- **Provider**: Hetzner, Contabo, or DigitalOcean
- **Specs**: 8 vCPU, 16GB RAM, 100GB SSD
- **Setup**: Docker Compose + Nginx reverse proxy

```bash
docker-compose up -d
```

### 3. Cheap GPU Server ($0.20-0.50/hour)

- **Provider**: RunPod, Vast.ai, or Lambda Labs
- **GPU**: RTX 3060 (12GB) or RTX 4060 Ti (16GB)
- **Performance**: <1s latency for most queries

### 4. Production (Scalable)

- **Kubernetes** with HPA for API pods
- **Ollama deployed as StatefulSet** with GPU node pool
- **Redis** for response caching
- **CDN** for frontend static assets

---

## ğŸ”’ Security Considerations

1. **Rate Limiting**: 10 req/min per IP for AI endpoints
2. **Input Validation**: Strict schemas with Pydantic
3. **No Secrets in Code**: All config via environment variables
4. **CORS**: Restricted to known origins in production
5. **Prompt Injection Protection**: Input sanitization

---

## ğŸ“ˆ Future Enhancements

1. **Fine-tuning**: Train on career guidance datasets
2. **Model Upgrades**: Hot-swap to Mixtral when GPU available
3. **Caching Layer**: Redis for common roadmap patterns
4. **User Feedback Loop**: Improve prompts based on ratings
5. **Multi-modal**: Resume parsing with vision models

---

## ğŸ“„ License

This project is **MIT Licensed**. 
The LLM (Mistral 7B) is **Apache 2.0 Licensed**.
