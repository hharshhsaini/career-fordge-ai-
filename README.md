# ğŸš€ CareerForge AI - Open Source Career Guidance Platform

> **100% Open-Source â€¢ Zero API Costs â€¢ Self-Hosted LLM**

AI-powered career guidance platform that generates personalized learning roadmaps, skills analysis, and interview preparation â€” all running on your own infrastructure with **zero usage costs**.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![LLM: Mistral 7B](https://img.shields.io/badge/LLM-Mistral%207B-blue)](https://mistral.ai/)
[![License: Apache 2.0](https://img.shields.io/badge/Model%20License-Apache%202.0-green)](https://www.apache.org/licenses/LICENSE-2.0)

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ¯ **Career Roadmaps** | 6-month personalized learning paths with weekly breakdowns |
| ğŸ“š **Skills Analysis** | Identify transferable skills and learning priorities |
| ğŸ’¼ **Interview Prep** | Technical & behavioral questions with answer frameworks |
| ğŸ§  **Knowledge Quizzes** | 15 MCQs per step with explanations (80% pass rate) |
| ğŸ¬ **YouTube Tutorials** | Auto-curated full course videos (no shorts!) |
| ğŸ“Š **Progress Tracking** | Visual completion tracking with PDF export |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚     â”‚   Backend API    â”‚     â”‚   LLM Service   â”‚
â”‚   (React/Vite)  â”‚â”€â”€â”€â”€â–¶â”‚   (FastAPI)      â”‚â”€â”€â”€â”€â–¶â”‚   (Ollama)      â”‚
â”‚   Port: 5173    â”‚     â”‚   Port: 8000     â”‚     â”‚   Port: 11434   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                 â”‚  Mistral 7B     â”‚
                                                 â”‚  (Apache 2.0)   â”‚
                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ† Why Mistral 7B?

| Model | License | VRAM | Speed | Context |
|-------|---------|------|-------|---------|
| **Mistral 7B** âœ“ | Apache 2.0 | 6GB | 127 tok/s | 32K |
| LLaMA 3 8B | Meta License* | 8GB | 67 tok/s | 8K |
| Mixtral 8x7B | Apache 2.0 | 24GB+ | 45 tok/s | 32K |

*Mistral 7B is truly open with zero licensing friction for commercial use.*

---

## ğŸš€ Quick Start

### Prerequisites

- **macOS/Linux** or WSL on Windows
- **8GB+ RAM** (16GB recommended)
- **Python 3.10+**
- **Node.js 18+**

### 1. Install Ollama & Model

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Start Ollama service
ollama serve

# Download Mistral 7B (4.1GB, takes 2-5 minutes)
ollama pull mistral:7b-instruct-v0.3-q4_K_M
```

### 2. Start Backend

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy environment file
cp .env.example .env

# Run the server
uvicorn main_v2:app --reload --port 8000
```

### 3. Start Frontend

```bash
cd frontend
npm install
npm run dev
```

### 4. Open the App

Visit **http://localhost:5173** ğŸ‰

---

## ğŸ“¡ API Endpoints

### Core AI Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/ai/roadmap` | Generate career roadmap |
| `POST` | `/api/ai/skills` | Analyze skills & recommendations |
| `POST` | `/api/ai/interview-prep` | Interview preparation guide |
| `POST` | `/api/ai/quiz` | Generate knowledge quiz |

### Health Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | System health status |
| `GET` | `/api/health/llm` | LLM service status |
| `GET` | `/api/health/models` | Available models |

### Legacy Compatibility

| Method | Endpoint | Maps To |
|--------|----------|---------|
| `POST` | `/generate-path` | `/api/ai/roadmap` |
| `POST` | `/generate-quiz` | `/api/ai/quiz` |

**Full API docs**: http://localhost:8000/docs

---

## ğŸ³ Docker Deployment

### Quick Start (All Services)

```bash
# Clone and run everything
docker-compose up -d

# Wait for model to download (first run only)
docker-compose logs -f model-loader
```

### Individual Services

```bash
# Just the LLM service
cd llm-service
docker-compose up -d

# Verify it's running
curl http://localhost:11434/api/tags
```

---

## â˜ï¸ Deployment Options

### 1. Local Machine (FREE)

- **Hardware**: 8GB RAM, any modern CPU
- **Performance**: ~3-5s per roadmap generation
- **Best for**: Development, personal use

### 2. Single VPS ($20-50/month)

```
Provider     RAM    vCPUs   Cost/mo
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Hetzner      16GB   4       $18
Contabo      16GB   4       $12
DigitalOcean 16GB   4       $48
```

### 3. GPU Cloud ($0.20-0.50/hour)

```
Provider   GPU          VRAM   Cost/hr
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RunPod     RTX 3060     12GB   $0.20
Vast.ai    RTX 3080     10GB   $0.25
Lambda     RTX 4090     24GB   $0.50
```

**GPU gives 10-20x faster inference!**

---

## ğŸ“ Project Structure

```
career-forge/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main_v2.py              # FastAPI app (open-source LLM)
â”‚   â”œâ”€â”€ config.py               # Environment configuration
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/             # API endpoint handlers
â”‚   â”‚   â””â”€â”€ schemas/            # Request/response models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm_service.py      # Ollama integration
â”‚   â”‚   â”œâ”€â”€ roadmap_service.py  # Roadmap generation
â”‚   â”‚   â”œâ”€â”€ skills_service.py   # Skills analysis
â”‚   â”‚   â”œâ”€â”€ interview_service.py # Interview prep
â”‚   â”‚   â””â”€â”€ quiz_service_v2.py  # Quiz generation
â”‚   â”œâ”€â”€ prompts/                # Prompt templates
â”‚   â””â”€â”€ utils/                  # Helpers
â”‚
â”œâ”€â”€ llm-service/
â”‚   â”œâ”€â”€ docker-compose.yml      # Ollama deployment
â”‚   â”œâ”€â”€ Modelfile               # Custom model config
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ setup.sh            # Installation script
â”‚       â”œâ”€â”€ health-check.sh     # Monitoring
â”‚       â””â”€â”€ benchmark.sh        # Performance testing
â”‚
â”œâ”€â”€ frontend/                   # React/Vite app
â”œâ”€â”€ docker-compose.yml          # Full stack deployment
â””â”€â”€ ARCHITECTURE.md             # Detailed architecture docs
```

---

## ğŸ”§ Configuration

All settings via environment variables:

```bash
# LLM Service
LLM_BASE_URL=http://localhost:11434
LLM_MODEL=mistral:7b-instruct-v0.3-q4_K_M
LLM_TIMEOUT=120

# API Server
API_PORT=8000
CORS_ORIGINS=http://localhost:5173

# Features
YOUTUBE_ENABLED=true
RATE_LIMIT=30
```

See `.env.example` for all options.

---

## ğŸ”’ Security

- âœ… Rate limiting on AI endpoints
- âœ… Input validation & sanitization
- âœ… Prompt injection protection
- âœ… No secrets in code
- âœ… CORS configuration
- âœ… Non-root Docker containers

---

## ğŸš€ Scaling Notes

### Horizontal Scaling

```yaml
# deploy.yaml (Kubernetes)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: careerforge-api
spec:
  replicas: 3  # Scale API pods
  ...
```

### Response Caching

Add Redis for caching common roadmaps:
```python
# Cache similar profile queries
cache_key = hash(user_profile)
if cached := redis.get(cache_key):
    return cached
```

### Model Upgrades

Hot-swap to stronger models when resources available:
```bash
# Upgrade to Mixtral (needs 24GB+ VRAM)
ollama pull mixtral:8x7b-instruct-v0.1-q4_K_M

# Update .env
LLM_MODEL=mixtral:8x7b-instruct-v0.1-q4_K_M
```

---

## ğŸ“¸ Screenshots

*Beautiful gradient UI with purple theme, 3D loading animations, interactive quiz modals, and progress visualization.*

---

## ğŸ› ï¸ Development

### Run Tests

```bash
cd backend
pytest tests/ -v
```

### Lint & Format

```bash
black .
isort .
mypy .
```

### Benchmark LLM

```bash
cd llm-service/scripts
./benchmark.sh
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request

---

## ğŸ“„ License

- **This Project**: MIT License
- **Mistral 7B Model**: Apache 2.0 License

---

## ğŸ‘¨â€ğŸ’» Author

**Harsh Saini**

Made with â¤ï¸ for developers who want AI without the API bill.

---

## ğŸ™ Acknowledgments

- [Mistral AI](https://mistral.ai/) for the amazing open-source model
- [Ollama](https://ollama.com/) for making local LLM deployment easy
- The open-source community for making this possible

---

*"BCâ€¦ ye banda serious hai."* ğŸš€
